{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plenoptic-Toolbox To D-NeRF dataset format\n",
    "\n",
    "\n",
    "#### Notes on D-NeRF dataset:\n",
    "\n",
    "In the nerfstudio DNeRF parser, `camera_angle_x` parameter (found in the transforms files) has a $1/tanh(0.5*x)$ relationship with the focal length. While I did mess around with this in [Desmos](https://www.desmos.com/calculator/xw0lodoghb) and initially selected a high $x=4.$ value. It didn't play well with kplanes (tested with scene contraction and varying near and far plane positions). In the end $x=0.6$ worked best despite how counter intuitive this is... The parameter is important for good rendering but is not directly recoverable from the nerfstudio dataset (it might be I just haven't looked into it).\n",
    "\n",
    "Otherwise the `rotation` parameter found for each frame doesn't seem to have any impact on performance (at least in the tests I ran with K-Planes, **this maybe different for other models!!!**)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Configuration\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the plenoptic toolbox (ptb) config and video files\n",
    "config_fp ='data/plenoptic_toolbox/161029_sports1/calibration_161029_sports1.json'\n",
    "video_fp = 'data/plenoptic_toolbox/161029_sports1/hdVideos/'\n",
    "# Set the video type\n",
    "if 'hdVideos' in video_fp:\n",
    "    camType = 'hd'\n",
    "elif 'vgaVideos' in video_fp:\n",
    "    camType = 'vga'\n",
    "else: # default currently assumes VGA camera dataset\n",
    "    camType = 'vga'\n",
    "# Set the output folder\n",
    "output_fp = 'data/plenoptic_toolbox/161029_sports1/dnerf/'\n",
    "\n",
    "# Assert input data exists\n",
    "assert os.path.exists(config_fp), AssertionError(f'Config Non-Existent : {config_fp}')\n",
    "assert os.path.exists(video_fp), AssertionError(f'Config Non-Existent : {video_fp}')\n",
    "\n",
    "\n",
    "# Construct folders (replace existing folders)\n",
    "os.makedirs(output_fp, exist_ok=True) # create root folder\n",
    "train_im_fp = output_fp+'train/'\n",
    "test_im_fp = output_fp+'test/'\n",
    "val_im_fp = output_fp+'val/'\n",
    "os.makedirs(train_im_fp, exist_ok=True) # create train, test and val folders\n",
    "os.makedirs(test_im_fp, exist_ok=True)\n",
    "os.makedirs(val_im_fp, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open(config_fp, 'r') as fp:\n",
    "    config = json.load(fp)\n",
    "\n",
    "# Initialise used_frame dict\n",
    "used_frames = {} # dict for storing \"[camera]\":[frame0, frame 12, frame 129, ...] (frames used in train and/or test)\n",
    "\n",
    "# Filter through camera data and store video pose data\n",
    "cameras = []\n",
    "for cam in config['cameras']:\n",
    "    if cam['type'] == camType:\n",
    "        # Construct a 4x4 transformation matrix\n",
    "        R = np.array(cam['R'])\n",
    "        t = np.array(cam['t'])\n",
    "        transformation_matrix = np.eye(4)\n",
    "        transformation_matrix[:3, :3] = R\n",
    "        transformation_matrix[:3, 3] = t.flatten()\n",
    "\n",
    "        # Store necessary data\n",
    "        cameras.append({\n",
    "            \"name\":cam['name'],\n",
    "            \"transformation_matrix\":transformation_matrix\n",
    "        })\n",
    "\n",
    "        # Initialise store for each camera\n",
    "        used_frames[cam['name']] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training data\n",
    "rotation = 0.3141592653589793\n",
    "camAngleX = 0.6911112070083618\n",
    "\n",
    "import cv2\n",
    "\n",
    "frameNum = 0\n",
    "loopflag = True # set this to a high value for now\n",
    "camNum = len(cameras)\n",
    "\n",
    "training_data = {\n",
    "    \"frames\":[],\n",
    "    \"camera_angle_x\": camAngleX,\n",
    "}\n",
    "\n",
    "while loopflag:\n",
    "    for i, cam in enumerate(cameras):\n",
    "        # Construct filepath to video\n",
    "        if camType == 'hd':\n",
    "            name_start = 'hd_'\n",
    "        elif camType == 'vga':\n",
    "            name_start = 'vga_'\n",
    "        else:\n",
    "            print('You need to select hd or vga selected')\n",
    "            exit()\n",
    "        \n",
    "        fp = video_fp+name_start+cam['name']+'.mp4'\n",
    "        assert os.path.exists(fp), AssertionError(f'Video Not Found: {fp}')\n",
    "        \n",
    "        # Get Number of cameras and number of frames\n",
    "        video = cv2.VideoCapture(str(fp))\n",
    "\n",
    "        # Get the total number of frames\n",
    "        if frameNum == 0:        \n",
    "            total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, frameNum)\n",
    "        ret, frame = video.read()\n",
    "\n",
    "        # Append data to training dict\n",
    "        training_data[\"frames\"].append(\n",
    "            {\n",
    "                \"file_path\":f'train/r_{frameNum}',\n",
    "                \"rotation\": rotation,\n",
    "                \"time\": float(frameNum/total_frames),\n",
    "                \"transform_matrix\":cam[\"transformation_matrix\"].tolist()\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        \n",
    "        cv2.imwrite(train_im_fp+f'r_{frameNum}.png', frame)\n",
    "        used_frames[cam['name']].append(frameNum)\n",
    "\n",
    "        frameNum += 1\n",
    "        \n",
    "        if frameNum == (total_frames):\n",
    "            loopflag = False\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Extract test and val data\n",
    "testNum = 100\n",
    "valNum = 100\n",
    "\n",
    "testing_data = {\n",
    "    \"frames\":[],\n",
    "    \"camera_angle_x\": camAngleX,\n",
    "}\n",
    "validation_data = {\n",
    "    \"frames\":[],\n",
    "    \"camera_angle_x\": camAngleX,\n",
    "}\n",
    "\n",
    "for j in range(testNum):\n",
    "    camNum = (j % len(cameras))\n",
    "    cam = cameras[camNum]\n",
    "    used_cam_frames = used_frames[cam['name']]\n",
    "\n",
    "    # Construct filepath to video\n",
    "    if camType == 'hd':\n",
    "        name_start = 'hd_'\n",
    "    elif camType == 'vga':\n",
    "        name_start = 'vga_'\n",
    "    else:\n",
    "        print('You need to select hd or vga selected')\n",
    "        exit()\n",
    "        \n",
    "    fp = video_fp+name_start+cam['name']+'.mp4'\n",
    "    assert os.path.exists(fp), AssertionError(f'Video Not Found: {fp}')\n",
    "    \n",
    "    # Get Number of cameras and number of frames\n",
    "    video = cv2.VideoCapture(str(fp))\n",
    "    \n",
    "    # Randomly generate a frame to extract (between 0 and # Frames)\n",
    "    frameNum = random.randint(0, total_frames-1)\n",
    "    \n",
    "    # If frame is already selected we need to generate new frame\n",
    "    while frameNum in used_cam_frames:\n",
    "        frameNum = random.randint(0, total_frames-1)\n",
    "\n",
    "    used_frames[cam['name']].append(frameNum)\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, frameNum)\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Append data to training dict\n",
    "    testing_data[\"frames\"].append(\n",
    "        {\n",
    "            \"file_path\":f'test/r_{frameNum}',\n",
    "            \"rotation\": rotation,\n",
    "\n",
    "            \"time\": float(frameNum/total_frames),\n",
    "            \"transform_matrix\":cam[\"transformation_matrix\"].tolist()\n",
    "        }\n",
    "    ) \n",
    "    cv2.imwrite(test_im_fp+f'r_{j}.png', frame)\n",
    "\n",
    "\n",
    "for j in range(valNum):\n",
    "    camNum = (j % len(cameras))\n",
    "    cam = cameras[camNum]\n",
    "    used_cam_frames = used_frames[cam['name']]\n",
    "\n",
    "    # Construct filepath to video\n",
    "    if camType == 'hd':\n",
    "        name_start = 'hd_'\n",
    "    elif camType == 'vga':\n",
    "        name_start = 'vga_'\n",
    "    else:\n",
    "        print('You need to select hd or vga selected')\n",
    "        exit()\n",
    "        \n",
    "    fp = video_fp+name_start+cam['name']+'.mp4'\n",
    "    assert os.path.exists(fp), AssertionError(f'Video Not Found: {fp}')\n",
    "    \n",
    "    # Get Number of cameras and number of frames\n",
    "    video = cv2.VideoCapture(str(fp))\n",
    "    \n",
    "    # Randomly generate a frame to extract (between 0 and # Frames)\n",
    "    frameNum = random.randint(0, total_frames-1)\n",
    "    \n",
    "    # If frame is already selected we need to generate new frame\n",
    "    while frameNum in used_cam_frames:\n",
    "        frameNum = random.randint(0, total_frames-1)\n",
    "\n",
    "    used_frames[cam['name']].append(frameNum)\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, frameNum)\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Append data to training dict\n",
    "    validation_data[\"frames\"].append(\n",
    "        {\n",
    "            \"file_path\":f'val/r_{frameNum}',\n",
    "            \"rotation\": rotation,\n",
    "            \"time\": float(frameNum/total_frames),\n",
    "            \"transform_matrix\":cam[\"transformation_matrix\"].tolist()\n",
    "        }\n",
    "    ) \n",
    "    cv2.imwrite(val_im_fp+f'r_{j}.png', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(output_fp+'transforms_train.json','w') as fp:\n",
    "    json.dump(training_data, fp)\n",
    "with open(output_fp+'transforms_test.json','w') as fp:\n",
    "    json.dump(testing_data, fp)\n",
    "with open(output_fp+'transforms_val.json','w') as fp:\n",
    "    json.dump(validation_data, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils_ import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO - think of a title\n",
    "\n",
    "**Args:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def handler(d_fp, o_fp, v_fp, img_fp, meth, rotation:float=0.0, camera_angle_x:float=0.0):\n",
    "    d_fp = Path(d_fp)\n",
    "    v_fp = Path(v_fp)\n",
    "    img_fp = d_fp / img_fp\n",
    "\n",
    "    transforms_fp = d_fp/'transforms.json'\n",
    "\n",
    "    # Sanity Checks\n",
    "    pathchecks([d_fp, v_fp, img_fp])\n",
    "    folderchecks([d_fp, img_fp])\n",
    "    \n",
    "    # meth = 'linear'\n",
    "    # Handle exhaustive method\n",
    "    if meth == 'exhaustive':\n",
    "        exhaustive(d_fp, o_fp, v_fp, img_fp,transforms_fp)    \n",
    "    elif meth == 'linear':\n",
    "        linear(d_fp, o_fp, v_fp, img_fp,transforms_fp, rotation=rotation, camera_angle_x=camera_angle_x)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
