{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nerfstudio To D-NeRF dataset\n",
    "\n",
    "Set Up:\n",
    "\n",
    "1. Installl Nerfstudio and activate environment\n",
    "2. Run this notebook with the nerfstudio conda environment\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Update configuration relative to desired parameters\n",
    "2. Run the method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Configuration\n",
    "---\n",
    "\n",
    "Information:\n",
    "1. `nerfstudio_fp` is the path **to the folder** containing `transforms.json`\n",
    "2. `output_fp` is the path to the folder you wish to write `transforms_train.json`, `transforms_test.json` and `transforms_val.json`\n",
    "3. `downscale_images_fp` is the folder name inside of you nerfstudio folder containing the downscaled images if you would rather save these than the original images. As dnerf format doesn't consider downscaled images, this will allow you to use them instead.\n",
    "4. `method` declares the way we recover the time values:\n",
    "    - `'exhaustive'`    : match image to frame (**super slow**)\n",
    "    - `'linear'`    : assign time given image name-index (**fast**) (e.g. image w/name `frame_{i}.png` is going to be at i/n time where n is the number of images and `i` is the index; this is the image-naming format used by nerfstudio-colamp process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "nerfstudio_fp ='path/to/folder/containing/tranform/file'\n",
    "video_fp = 'path/to/video.mp4'\n",
    "output_fp = 'path/to/write/transform/to'\n",
    "\n",
    "downscale_images_fp = 'path/to/folder/containing/downscalled/images'\n",
    "\n",
    "method = 'exhaustive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nerfstudio_fp ='data/boat_colmap/'\n",
    "video_fp = 'data/boat/boat.mp4'\n",
    "output_fp = 'data/boat_colmap_/'\n",
    "\n",
    "downscale_images_fp = 'images/'\n",
    "\n",
    "method = 'exhaustive'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# View the code\n",
    "---\n",
    "\n",
    "Information:\n",
    "1. Import dependencies. *Make sure nerfstudio has been downloaded*\n",
    "2. View the functions\n",
    "3. Change the functions (optional)\n",
    "4. Run the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils_ import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exhaustive Image Search\n",
    "\n",
    "**Args:**\n",
    "- d_fp, v_fp, img_fp: Path, previously discussed\n",
    "- transfors_fp: Path, path to transforms file\n",
    "\n",
    "**Notes:**\n",
    "1. Exhaustive search matches each image (e.g. `frame_0000.png`, `frame_0001.png`, ... ) to each frame in a video. \n",
    "2. Each image is a frame with png compression so direct image to frame comparison isn't possible\n",
    "3. Instead we compare w/ SSIM.\n",
    "4. This means:\n",
    "\n",
    "    a. Overlapping frames (such as monocular stationary camera with negligible dynamic motion) will have the same SSIM score and so we will get several frames which match\n",
    "        \n",
    "    b. We select the earliest occuring frame match as the time of the png image\n",
    "    \n",
    "    c. We accept that this may not always be the case so we add a threshold, whereby we search for the earliest match where SSIM = 1.0, when this is not the case max(SSIM) > 0.98 is selected.\n",
    "    \n",
    "    d. Theoretically, this shouldn't be an issue for NeRF as SSIM threshold is high\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exhaustive(d_fp, o_fp, v_fp, img_fp, transforms_fp, shuffle:bool=True):\n",
    "    assert not os.path.exists(o_fp), 'Folder already exists, delete folder to run'\n",
    "\n",
    "    os.makedirs(o_fp)\n",
    "    with open(transforms_fp) as fp:\n",
    "        contents = fp.read()\n",
    "    transforms = json.loads(contents)\n",
    "    img_frames = transforms['frames'] # Directly access frame data\n",
    "\n",
    "    # Initialise opencv video object\n",
    "    video = cv2.VideoCapture(str(v_fp))\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f'Total number of frames to process {total_frames} \\n Total number of images to process {len(img_frames)}')\n",
    "\n",
    "\n",
    "    video_frame_counter = 0\n",
    "    matches = []\n",
    "\n",
    "    # Sort img_frames by filepath name\n",
    "    filenum = []\n",
    "    for img in img_frames:\n",
    "        num = img['file_path'].split('/')[-1].split('.')[-2].split('_')[-1]\n",
    "        filenum.append(int(num))\n",
    "    img_frames = [img for _, img in sorted(zip(filenum, img_frames))]\n",
    "        \n",
    "\n",
    "    iterator = tqdm(enumerate(img_frames))\n",
    "    # loop through each image in our colmap dataset\n",
    "    for idx, img in iterator:\n",
    "        fp = img['file_path']\n",
    "        image = cv2.imread(fp, cv2.IMREAD_GRAYSCALE) # load image greyscale\n",
    "\n",
    "        SSIM = {\n",
    "            'max': 0.,\n",
    "            'idxs':[]\n",
    "        }\n",
    "        for idx_video in range(video_frame_counter, total_frames):\n",
    "            # Fetch frame from video\n",
    "            video.set(cv2.CAP_PROP_FRAME_COUNT, i)\n",
    "            ret, frame = video.read()\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # load frame greyscale\n",
    "\n",
    "            # Get SSIM\n",
    "            ssim_res = ssim(image, frame)\n",
    "\n",
    "            # Process SSIM\n",
    "            if ssim_res == 1.0: # if we meet ideal match\n",
    "                SSIM['max'] = 1.\n",
    "                SSIM['idxs'] = [idx_video] \n",
    "                break\n",
    "            elif ssim_res > SSIM: # if we have a new max\n",
    "                SSIM['max'] = ssim_res\n",
    "                SSIM['idxs'] = [idx_video]\n",
    "            elif ssim_res == SSIM: # if we have the same max\n",
    "                SSIM['idxs'].append(idx_video)\n",
    "        \n",
    "\n",
    "        if SSIM['max'] < 0.98:\n",
    "            print(f'Image {idx} has no match: consider lowering threshold')\n",
    "        else:\n",
    "            idx_video = min(SSIM['idxs'])\n",
    "            matches.append({\n",
    "                \"frame\" : float(idx_video/total_frames),\n",
    "                \"image\" : idx\n",
    "                })\n",
    "\n",
    "    # shuffle data\n",
    "    if shuffle == True:\n",
    "        random.shuffle(matches)\n",
    "\n",
    "    # train split\n",
    "    train_split = 0.9\n",
    "    train_idx = int(train_split * len(matches))\n",
    "    train_data = matches[:train_idx]\n",
    "    # test split (on remaining data)\n",
    "    test_split = 0.9\n",
    "    test_index = train_idx + int(test_split * (len(matches) - len(train_data)))\n",
    "    test_data =  matches[train_idx : test_index]\n",
    "    # val split\n",
    "    val_data = matches[test_index:]\n",
    "\n",
    "\n",
    "    # Construct transform files\n",
    "    local_properties = {\n",
    "        \"roation\": 0.0,\n",
    "    }\n",
    "    data = [train_data, test_data, val_data]\n",
    "    for idx, d in enumerate(data):\n",
    "        file_ = {\n",
    "            \"camera_angle_x\": 0.0,\n",
    "            \"frames\":[]\n",
    "        }\n",
    "        # file_path\n",
    "        if idx == 0: file_path = Path(o_fp) / 'transforms_train.json'\n",
    "        elif idx == 1: file_path = Path(o_fp) / 'transforms_test.json'\n",
    "        elif idx == 2: file_path = Path(o_fp) / 'transforms_val.json'\n",
    "        \n",
    "        for match_idx in d:\n",
    "            img_data = img_frames[match_idx]\n",
    "            time = float(img_data['idx'] / total_frames)\n",
    "            fname = img_data['data']['file_path'].split('/')[-1]\n",
    "            \n",
    "            file_[\"frames\"].append({\n",
    "            \"file_path\":f'./train/{fname}',\n",
    "            \"rotation\": local_properties['rotation'],\n",
    "            \"time\":time,\n",
    "            \"transform_matrix\":img_data['data']['transform_matrix']\n",
    "        })\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handler for nerfstudio2dnerf\n",
    "\n",
    "**Args:**\n",
    "- `d_fp`, Path, path to `transforms.json` **folder**\n",
    "- `o_fp`, Path, path to output folder\n",
    "- `v_fp`, Path, path to video\n",
    "- `img_fp`, Path, path to image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'data/boat_colmap_/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/barry/Desktop/DataCollection/datacollection/nstudio2dnerf.ipynb Cell 10\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/barry/Desktop/DataCollection/datacollection/nstudio2dnerf.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mexhaustive\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/barry/Desktop/DataCollection/datacollection/nstudio2dnerf.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         exhaustive(d_fp, o_fp, v_fp, img_fp,transforms_fp)    \n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/barry/Desktop/DataCollection/datacollection/nstudio2dnerf.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m handler(nerfstudio_fp, output_fp, video_fp, downscale_images_fp, method)\n",
      "\u001b[1;32m/home/barry/Desktop/DataCollection/datacollection/nstudio2dnerf.ipynb Cell 10\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/barry/Desktop/DataCollection/datacollection/nstudio2dnerf.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Handle exhaustive method\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/barry/Desktop/DataCollection/datacollection/nstudio2dnerf.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mexhaustive\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/barry/Desktop/DataCollection/datacollection/nstudio2dnerf.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     exhaustive(d_fp, o_fp, v_fp, img_fp,transforms_fp)\n",
      "\u001b[1;32m/home/barry/Desktop/DataCollection/datacollection/nstudio2dnerf.ipynb Cell 10\u001b[0m in \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/barry/Desktop/DataCollection/datacollection/nstudio2dnerf.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaustive\u001b[39m(d_fp, o_fp, v_fp, img_fp, transforms_fp):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/barry/Desktop/DataCollection/datacollection/nstudio2dnerf.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     os\u001b[39m.\u001b[39;49mmakedirs(o_fp)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/barry/Desktop/DataCollection/datacollection/nstudio2dnerf.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(transforms_fp) \u001b[39mas\u001b[39;00m fp:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/barry/Desktop/DataCollection/datacollection/nstudio2dnerf.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         contents \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[0;32m~/anaconda3/envs/nerfstudio/lib/python3.8/os.py:223\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     mkdir(name, mode)\n\u001b[1;32m    224\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    227\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exist_ok \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'data/boat_colmap_/'"
     ]
    }
   ],
   "source": [
    "def handler(d_fp, o_fp, v_fp, img_fp, meth):\n",
    "    d_fp = Path(d_fp)\n",
    "    v_fp = Path(v_fp)\n",
    "    img_fp = d_fp / img_fp\n",
    "\n",
    "    transforms_fp = d_fp/'transforms.json'\n",
    "\n",
    "    # Sanity Checks\n",
    "    pathchecks([d_fp, v_fp, img_fp])\n",
    "    folderchecks([d_fp, img_fp])\n",
    "    \n",
    "    # Handle exhaustive method\n",
    "    if meth == 'exhaustive':\n",
    "        exhaustive(d_fp, o_fp, v_fp, img_fp,transforms_fp)    \n",
    "\n",
    "handler(nerfstudio_fp, output_fp, video_fp, downscale_images_fp, method)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Run the code\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
