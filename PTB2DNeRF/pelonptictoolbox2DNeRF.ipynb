{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plenoptic-Toolbox To D-NeRF dataset format\n",
    "\n",
    "\n",
    "#### Notes on D-NeRF dataset:\n",
    "\n",
    "In the nerfstudio DNeRF parser, `camera_angle_x` parameter (found in the transforms files) has a $1/2*tanh(0.5*x)$ relationship with the focal length. As the PTB dataset does not come with this, I use the nerfstudio repository to perform camera calibration using the 0th frame of all the videos. This will give us `(f_x, f_y, c_x, c_y)` (the focal and pixel area intrinsics) which replace the `camera__angle_x` parametr present in the initial D-NeRF dataset\n",
    "\n",
    "Otherwise the `rotation` parameter found for each frame doesn't seem to have any impact on performance (at least in the tests I ran with K-Planes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Configuration\n",
    "---\n",
    "\n",
    "1. Set-Up directories\n",
    "2. Filter through the PTB dataset and re-construct the transformation matrix.\n",
    "3. Store training data\n",
    "4. Repeat for Test and Val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the plenoptic toolbox (ptb) config and video files\n",
    "config_fp ='data/plenoptic_toolbox/161029_sports1/calibration_161029_sports1.json'\n",
    "video_fp = 'data/plenoptic_toolbox/161029_sports1/hdVideos/'\n",
    "# Set the video type\n",
    "if 'hdVideos' in video_fp:\n",
    "    camType = 'hd'\n",
    "elif 'vgaVideos' in video_fp:\n",
    "    camType = 'vga'\n",
    "else: # default currently assumes VGA camera dataset\n",
    "    camType = 'vga'\n",
    "# Set the output folder\n",
    "output_fp = 'data/plenoptic_toolbox/161029_sports1/dnerf/'\n",
    "\n",
    "# Assert input data exists\n",
    "assert os.path.exists(config_fp), AssertionError(f'Config Non-Existent : {config_fp}')\n",
    "assert os.path.exists(video_fp), AssertionError(f'Config Non-Existent : {video_fp}')\n",
    "\n",
    "\n",
    "# Construct folders (replace existing folders)\n",
    "os.makedirs(output_fp, exist_ok=True) # create root folder\n",
    "train_im_fp = output_fp+'train/'\n",
    "test_im_fp = output_fp+'test/'\n",
    "val_im_fp = output_fp+'val/'\n",
    "os.makedirs(train_im_fp, exist_ok=True) # create train, test and val folders\n",
    "os.makedirs(test_im_fp, exist_ok=True)\n",
    "os.makedirs(val_im_fp, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open(config_fp, 'r') as fp:\n",
    "    config = json.load(fp)\n",
    "\n",
    "# Initialise used_frame dict\n",
    "used_frames = {} # dict for storing \"[camera]\":[frame0, frame 12, frame 129, ...] (frames used in train and/or test)\n",
    "\n",
    "# Filter through camera data and store video pose data\n",
    "cameras = []\n",
    "for cam in config['cameras']:\n",
    "    if cam['type'] == camType:\n",
    "        # Construct a 4x4 transformation matrix\n",
    "        R = np.matrix(cam['R'])\n",
    "        t = np.array(cam['t'])\n",
    "        transformation_matrix = np.eye(4)\n",
    "        transformation_matrix[:3, :3] = R.transpose()\n",
    "        cc = (-R.transpose()*t)\n",
    "        transformation_matrix[:3, 3] =cc.flatten()/80. # Here we re-scale scene from 300x300x300 to 4x4x4 (not exactly 4 but nearly)\n",
    "        \n",
    "        # Store necessary data\n",
    "        cameras.append({\n",
    "            \"name\":cam['name'],\n",
    "            \"transformation_matrix\":transformation_matrix\n",
    "        })\n",
    "        # Initialise store for each camera\n",
    "        used_frames[cam['name']] = []\n",
    "\n",
    "# Initialise the Dictionaries that will hold our training, testing and validation data\n",
    "training_data = {\n",
    "    \"camera_angle_x\":0.1,\n",
    "    \"w\": 1920, # Intrinsics generate by nerfstudio\n",
    "    \"h\": 1080,\n",
    "    \"fl_x\": 1468.757320423469,\n",
    "    \"fl_y\": 1471.8049431235877,\n",
    "    \"cx\": 938.9616276596577,\n",
    "    \"cy\": 562.453456691303,\n",
    "    \"k1\": -0.2530330313118452,\n",
    "    \"k2\": 0.1464548200867903,\n",
    "    \"p1\": 0.00011976648210367369,\n",
    "    \"p2\": 6.6743379744858146e-06,\n",
    "    \"camera_model\": \"OPENCV\",\n",
    "    \"frames\":[]\n",
    "}\n",
    "testing_data = {\n",
    "    \"camera_angle_x\":0.1,\n",
    "    \"w\": 1920, # Intrinsics generate by nerfstudio\n",
    "    \"h\": 1080,\n",
    "    \"fl_x\": 1468.757320423469,\n",
    "    \"fl_y\": 1471.8049431235877,\n",
    "    \"cx\": 938.9616276596577,\n",
    "    \"cy\": 562.453456691303,\n",
    "    \"k1\": -0.2530330313118452,\n",
    "    \"k2\": 0.1464548200867903,\n",
    "    \"p1\": 0.00011976648210367369,\n",
    "    \"p2\": 6.6743379744858146e-06,\n",
    "    \"camera_model\": \"OPENCV\",\n",
    "    \"frames\":[]\n",
    "}\n",
    "validation_data = {\n",
    "    \"camera_angle_x\":0.1,\n",
    "    \"w\": 1920, # Intrinsics generate by nerfstudio\n",
    "    \"h\": 1080,\n",
    "    \"fl_x\": 1468.757320423469,\n",
    "    \"fl_y\": 1471.8049431235877,\n",
    "    \"cx\": 938.9616276596577,\n",
    "    \"cy\": 562.453456691303,\n",
    "    \"k1\": -0.2530330313118452,\n",
    "    \"k2\": 0.1464548200867903,\n",
    "    \"p1\": 0.00011976648210367369,\n",
    "    \"p2\": 6.6743379744858146e-06,\n",
    "    \"camera_model\": \"OPENCV\",\n",
    "    \"frames\":[]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test-Val Split\n",
    "\n",
    "1. We select one camera for validation, one camera for testing and the remainder for training.\n",
    "2. Additionally 10 frames from each training camera will be selected for validation and testion (5 each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training data\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "frameNum = 0\n",
    "camNum = len(cameras)\n",
    "\n",
    "# Video is 180 frames\n",
    "total_frames = 20\n",
    "\n",
    "# Arbitrary selection\n",
    "testCamera = 2\n",
    "valCamera = 18\n",
    "assert (testCamera < camNum) and (valCamera < camNum), AssertionError('Either testCamera or valCamera is set incorrectly (above camNum)')\n",
    "assert (testCamera >= 0) and (valCamera >= 0), AssertionError('Either testCamera or valCamera is set incorrectly (below 0)')\n",
    "\n",
    "rotation = 0.3141592653589793\n",
    "\n",
    "for i, cam in enumerate(cameras):\n",
    "    # Construct filepath to video\n",
    "    name_start = camType+'_'\n",
    "    fp = video_fp+name_start+cam['name']+'.mp4'\n",
    "    assert os.path.exists(fp), AssertionError(f'Video Not Found: {fp}')\n",
    "    \n",
    "    # Get Number of cameras and number of frames\n",
    "    video = cv2.VideoCapture(str(fp))\n",
    "\n",
    "    # Get the total number of frames for the video\n",
    "    # total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT)) # Uncomment if you want to use the whole video\n",
    "\n",
    "    # Set the destination folder for images\n",
    "    if i == testCamera:\n",
    "        folder = 'test/'\n",
    "    elif i == valCamera:\n",
    "        folder = 'val/'\n",
    "    else:\n",
    "        folder = 'train/'\n",
    "\n",
    "        # Determine the frames from each video to associate with validation or testing\n",
    "        test_val_frames = random.sample(range(total_frames), 10)\n",
    "        test_frames = test_val_frames[:5]\n",
    "        val_frames = test_val_frames[5:]\n",
    "    \n",
    "    # Cycle through each frame as store w.r.t val_frames, test_frames and the selected camera\n",
    "    for frameNum in range(total_frames):\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, frameNum)\n",
    "        ret, frame = video.read()\n",
    "\n",
    "        # Set the destination folder of the images\n",
    "        localDestinationFolder = folder\n",
    "        if folder == 'train/':\n",
    "            if frameNum in test_frames:\n",
    "                localDestinationFolder = 'test/'\n",
    "            elif frameNum in val_frames:\n",
    "                localDestinationFolder = 'val/'\n",
    "        destinationFolder = output_fp + localDestinationFolder # E.g. 'dnerf/[val/train/test]/'\n",
    "        cv2.imwrite(destinationFolder+f'{cam[\"name\"]}_{frameNum}.png', frame)\n",
    "        \n",
    "        frameData = {\n",
    "            \"file_path\":f'{localDestinationFolder}{cam[\"name\"]}_{frameNum}',\n",
    "            \"rotation\": rotation,\n",
    "            \"time\": float(frameNum/total_frames),\n",
    "            \"transform_matrix\":cam[\"transformation_matrix\"].tolist()\n",
    "        }\n",
    "        \n",
    "        if i == testCamera:\n",
    "            testing_data[\"frames\"].append(\n",
    "                frameData\n",
    "            )\n",
    "        elif i == valCamera:\n",
    "            validation_data[\"frames\"].append(\n",
    "                frameData\n",
    "            )\n",
    "        else:\n",
    "            training_data[\"frames\"].append(\n",
    "                frameData\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_fp+'transforms_train.json','w') as fp:\n",
    "    json.dump(training_data, fp)\n",
    "with open(output_fp+'transforms_test.json','w') as fp:\n",
    "    json.dump(testing_data, fp)\n",
    "with open(output_fp+'transforms_val.json','w') as fp:\n",
    "    json.dump(validation_data, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
